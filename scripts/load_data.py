from rdflib import Graph
import requests
import os

# Configuration Fuseki
FUSEKI_ENDPOINT = "http://localhost:3030/eco-ontology"
FUSEKI_DATA = f"{FUSEKI_ENDPOINT}/data"
FUSEKI_UPDATE = f"{FUSEKI_ENDPOINT}/update"

def load_ontology_to_fuseki():
    try:
        # Charger l'ontologie en ignorant les erreurs de date
        g = Graph()
        print("Chargement du fichier RDF...")
        
        # Parser en ignorant les erreurs
        g.parse("../data/eco-ontology.rdf", format="xml", errors='ignore')
        print(f"Ontologie charg√©e: {len(g)} triplets trouv√©s")
        
        # Upload vers Fuseki par lots de triplets
        print("Upload des donn√©es vers Fuseki...")
        
        # M√©thode 1: Utiliser SPARQL INSERT pour chaque triplet
        success_count = 0
        error_count = 0
        
        for triple in g:
            try:
                subject = triple[0].n3()
                predicate = triple[1].n3()
                obj = triple[2].n3()
                
                # Cr√©er la requ√™te INSERT
                insert_query = f"""
                INSERT DATA {{
                    {subject} {predicate} {obj} .
                }}
                """
                
                headers = {
                    'Content-Type': 'application/sparql-update'
                }
                
                response = requests.post(FUSEKI_UPDATE, data=insert_query, headers=headers)
                
                if response.status_code in [200, 204]:
                    success_count += 1
                else:
                    error_count += 1
                    print(f"Erreur avec le triplet: {triple}")
                    
            except Exception as e:
                error_count += 1
                continue
        
        print(f"‚úÖ Upload termin√©: {success_count} triplets charg√©s, {error_count} erreurs")
        
        # V√©rifier que les donn√©es sont bien charg√©es
        test_query = "SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }"
        headers = {'Accept': 'application/json'}
        response = requests.get(f"{FUSEKI_ENDPOINT}/query", params={'query': test_query}, headers=headers)
        
        if response.status_code == 200:
            data = response.json()
            count = data['results']['bindings'][0]['count']['value']
            print(f"üìä Total des triplets dans Fuseki: {count}")
            
    except Exception as e:
        print(f"‚ùå Erreur: {str(e)}")

def clear_dataset():
    """Vider le dataset avant de charger les nouvelles donn√©es"""
    try:
        clear_query = "CLEAR ALL"
        
        headers = {
            'Content-Type': 'application/sparql-update'
        }
        
        response = requests.post(FUSEKI_UPDATE, data=clear_query, headers=headers)
        
        if response.status_code in [200, 204]:
            print("‚úÖ Dataset vid√© avec succ√®s")
        else:
            print(f"‚ö†Ô∏è Impossible de vider le dataset: {response.status_code}")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du vidage: {str(e)}")

def test_fuseki_connection():
    """Tester la connexion √† Fuseki"""
    try:
        response = requests.get(FUSEKI_ENDPOINT)
        if response.status_code == 200:
            print("‚úÖ Connexion √† Fuseki r√©ussie")
            return True
        else:
            print(f"‚ùå Fuseki ne r√©pond pas: {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Impossible de se connecter √† Fuseki: {str(e)}")
        return False

if __name__ == '__main__':
    print("üöÄ D√©but du chargement des donn√©es...")
    
    if test_fuseki_connection():
        clear_dataset()
        load_ontology_to_fuseki()
    else:
        print("‚ùå Veuillez d√©marrer Fuseki d'abord: ./fuseki-server")